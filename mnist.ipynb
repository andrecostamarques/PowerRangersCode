{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16734994",
   "metadata": {},
   "source": [
    "# MNIST With Pytorch: First steps\n",
    "In this notebook, we aim to learn the basics of PyTorch for computer vision using the famous MNIST dataset—an image classification task involving handwritten digits (0 to 9)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193d8f86",
   "metadata": {},
   "source": [
    "## The Data\n",
    "To pull the data, we need to go through the following steps:\n",
    "1. Download the dataset;\n",
    "2. Divide in training and test data(for further validation);\n",
    "3. Preprocessing;\n",
    "\n",
    "### 1. Download the dataset\n",
    "MNIST is alwready availabel with *torchvision.datasets*. It can be downloaded with the `datasets.MNIST` class. With this class, we can use a handy pipeline that downloads MNIST, saves it at a local directory, defines if it is for training or validation, and apply a preprocessing.\n",
    "\n",
    "### 2. Divide in training and test data\n",
    "It is necessary to divide the dataset into training part and test part to ensure that no test data interferes with training (causing data leakage). To do this, we can use the `DataLoader` class, passing the data, the batch size (for further training) and shuffle to training data. Shuffle is important to garantee that the model will not learn a sequential pattern of the dataset.\n",
    "\n",
    "### 3. Preprocessing\n",
    "With this dataset, we applied a pipeline with `ToTensor()` to transform image data to tensors with values between [0, 1], and `Normalize((0,), (1,))` to normalize with **mean=0** and **std=1** (a commum practice to speed up traning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "eecd4443",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Imports\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Defines transform pipeline\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0,), (1,))\n",
    "])\n",
    "\n",
    "# Download and transform\n",
    "train_dataset = datasets.MNIST(\n",
    "    root='./data', train=True, download=True, transform=transform\n",
    ")\n",
    "test_dataset = datasets.MNIST(\n",
    "    root='./data', train=False, download=True, transform=transform\n",
    ")\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4b7663",
   "metadata": {},
   "source": [
    "## Visualizing\n",
    "We can use matplotlib to visualize some example images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f53edaa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x200 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to plot images with its lables\n",
    "def show_images(images, labels):\n",
    "    fig, axes = plt.subplots(1, len(images), figsize=(10, 2))\n",
    "    for img, label, ax in zip(images, labels, axes):\n",
    "        ax.imshow(img.squeeze(), cmap='gray')\n",
    "        ax.set_title(f'Label: {label}')\n",
    "        ax.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Get a batch of images from the training data loader\n",
    "data_iter = iter(train_loader)\n",
    "images, labels = next(data_iter)\n",
    "\n",
    "# Display the first 5 images with its labels\n",
    "show_images(images[:5], labels[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e700a67e",
   "metadata": {},
   "source": [
    "## Defining a Neural Network\n",
    "In Pytorch, a model (in our case a neural network) is defined by a class that inherits `nn.Module`. This class works like a blueprint for a pytorch model and requires at least `__init__()` and `foward()` method implementations.\n",
    "\n",
    "### The constructor\n",
    "In `__init__()` we can define the layers of our model. In this example, we used the following architecture:\n",
    "\n",
    "- **1º Layer:** A fully connected layer (defined by `nn.Linear` class) for feature extraction **[784 -> 128]**;<br>\n",
    "- **ReLU:** A activation function for non-linearity **[128 -> 128]**;<br>\n",
    "- **2º Layer:** A fully connected layer for final classess features **[128 -> 10]**; <br>\n",
    "- **Softamx:** A activation function to classify the image **[10 -> 10]**.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14418f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)  # Flatten the input\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return self.softmax(x)\n",
    "\n",
    "model = SimpleNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14141296",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "debcefd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.NLLLoss()  # Negative Log-Likelihood Loss\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a312719b",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7988a5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.46601869347793207\n",
      "Epoch 2, Loss: 0.22893040021583597\n",
      "Epoch 3, Loss: 0.17297790620499837\n",
      "Epoch 4, Loss: 0.13899957001415778\n",
      "Epoch 5, Loss: 0.1164374014795589\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    print(f'Epoch {epoch + 1}, Loss: {running_loss / len(train_loader)}')\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76151672",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8f9c6bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 92.27%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy on test set: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0a371d",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "- Implement a MNIST solution with CNNs\n",
    "- Implement a solution for another dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PowerRanger-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
